{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4embtkV0pNxM"
   },
   "source": [
    "Deep Learning\n",
    "=============\n",
    "\n",
    "Assignment 4\n",
    "------------\n",
    "\n",
    "Previously in `2_fullyconnected.ipynb` and `3_regularization.ipynb`, we trained fully connected networks to classify [notMNIST](http://yaroslavvb.blogspot.com/2011/09/notmnist-dataset.html) characters.\n",
    "\n",
    "The goal of this assignment is make the neural network convolutional."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cellView": "both",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "tm2CQN_Cpwj0"
   },
   "outputs": [],
   "source": [
    "# These are all the modules we'll be using later. Make sure you can import them\n",
    "# before proceeding further.\n",
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from six.moves import cPickle as pickle\n",
    "from six.moves import range\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import winsound\n",
    "import time\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "cellView": "both",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 11948,
     "status": "ok",
     "timestamp": 1446658914837,
     "user": {
      "color": "",
      "displayName": "",
      "isAnonymous": false,
      "isMe": true,
      "permissionId": "",
      "photoUrl": "",
      "sessionId": "0",
      "userId": ""
     },
     "user_tz": 480
    },
    "id": "y3-cj1bpmuxc",
    "outputId": "016b1a51-0290-4b08-efdb-8c95ffc3cd01"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set (300000, 28, 28) (300000,)\n",
      "Validation set (10000, 28, 28) (10000,)\n",
      "Test set (10000, 28, 28) (10000,)\n"
     ]
    }
   ],
   "source": [
    "pickle_file = 'D:/Libraries/Documents/Tensorflow/notMNIST_data/notMNIST.pickle'\n",
    "\n",
    "with open(pickle_file, 'rb') as f:\n",
    "  save = pickle.load(f)\n",
    "  train_dataset = save['train_dataset']\n",
    "  train_labels = save['train_labels']\n",
    "  valid_dataset = save['valid_dataset']\n",
    "  valid_labels = save['valid_labels']\n",
    "  test_dataset = save['test_dataset']\n",
    "  test_labels = save['test_labels']\n",
    "  del save  # hint to help gc free up memory\n",
    "  print('Training set', train_dataset.shape, train_labels.shape)\n",
    "  print('Validation set', valid_dataset.shape, valid_labels.shape)\n",
    "  print('Test set', test_dataset.shape, test_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "L7aHrm6nGDMB"
   },
   "source": [
    "Reformat into a TensorFlow-friendly shape:\n",
    "- convolutions need the image data formatted as a cube (width by height by #channels)\n",
    "- labels as float 1-hot encodings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "cellView": "both",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 11952,
     "status": "ok",
     "timestamp": 1446658914857,
     "user": {
      "color": "",
      "displayName": "",
      "isAnonymous": false,
      "isMe": true,
      "permissionId": "",
      "photoUrl": "",
      "sessionId": "0",
      "userId": ""
     },
     "user_tz": 480
    },
    "id": "IRSyYiIIGIzS",
    "outputId": "650a208c-8359-4852-f4f5-8bf10e80ef6c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set (300000, 28, 28, 1) (300000, 10)\n",
      "Validation set (10000, 28, 28, 1) (10000, 10)\n",
      "Test set (10000, 28, 28, 1) (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "image_size = 28\n",
    "num_labels = 10\n",
    "num_channels = 1 # grayscale\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def reformat(dataset, labels):\n",
    "  dataset = dataset.reshape(\n",
    "    (-1, image_size, image_size, num_channels)).astype(np.float32)\n",
    "  labels = (np.arange(num_labels) == labels[:,None]).astype(np.float32)\n",
    "  return dataset, labels\n",
    "train_dataset, train_labels = reformat(train_dataset, train_labels)\n",
    "valid_dataset, valid_labels = reformat(valid_dataset, valid_labels)\n",
    "test_dataset, test_labels = reformat(test_dataset, test_labels)\n",
    "print('Training set', train_dataset.shape, train_labels.shape)\n",
    "print('Validation set', valid_dataset.shape, valid_labels.shape)\n",
    "print('Test set', test_dataset.shape, test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "cellView": "both",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "AgQDIREv02p1"
   },
   "outputs": [],
   "source": [
    "def accuracy(predictions, labels):\n",
    "  return (100.0 * np.sum(np.argmax(predictions, 1) == np.argmax(labels, 1))\n",
    "          / predictions.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5rhgjmROXu2O"
   },
   "source": [
    "Let's build a small network with two convolutional layers, followed by one fully connected layer. Convolutional networks are more expensive computationally, so we'll limit its depth and number of fully connected nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "cellView": "both",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "IZYv70SvvOan"
   },
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "patch_size = 5\n",
    "depth = 16\n",
    "num_hidden = 64\n",
    "\n",
    "graph = tf.Graph()\n",
    "\n",
    "with graph.as_default():\n",
    "\n",
    "  # Input data.\n",
    "  tf_train_dataset = tf.placeholder(\n",
    "    tf.float32, shape=(batch_size, image_size, image_size, num_channels))\n",
    "  tf_train_labels = tf.placeholder(tf.float32, shape=(batch_size, num_labels))\n",
    "  tf_valid_dataset = tf.constant(valid_dataset)\n",
    "  tf_test_dataset = tf.constant(test_dataset)\n",
    "  \n",
    "  # Variables.\n",
    "  layer1_weights = tf.Variable(tf.truncated_normal(\n",
    "      [patch_size, patch_size, num_channels, depth], stddev=0.1))\n",
    "  layer1_biases = tf.Variable(tf.zeros([depth]))\n",
    "  layer2_weights = tf.Variable(tf.truncated_normal(\n",
    "      [patch_size, patch_size, depth, depth], stddev=0.1))\n",
    "  layer2_biases = tf.Variable(tf.constant(1.0, shape=[depth]))\n",
    "  layer3_weights = tf.Variable(tf.truncated_normal(\n",
    "      [image_size // 4 * image_size // 4 * depth, num_hidden], stddev=0.1))\n",
    "  layer3_biases = tf.Variable(tf.constant(1.0, shape=[num_hidden]))\n",
    "  layer4_weights = tf.Variable(tf.truncated_normal(\n",
    "      [num_hidden, num_labels], stddev=0.1))\n",
    "  layer4_biases = tf.Variable(tf.constant(1.0, shape=[num_labels]))\n",
    "  \n",
    "  # Model.\n",
    "  def model(data):\n",
    "    conv = tf.nn.conv2d(data, layer1_weights, [1, 2, 2, 1], padding='SAME')#stride of 2\n",
    "    hidden = tf.nn.relu(conv + layer1_biases)\n",
    "    conv = tf.nn.conv2d(hidden, layer2_weights, [1, 2, 2, 1], padding='SAME')#stride of 2\n",
    "    hidden = tf.nn.relu(conv + layer2_biases)\n",
    "    shape = hidden.get_shape().as_list()\n",
    "    reshape = tf.reshape(hidden, [shape[0], shape[1] * shape[2] * shape[3]])#flatten the image for the FC layers\n",
    "    hidden = tf.nn.relu(tf.matmul(reshape, layer3_weights) + layer3_biases)\n",
    "    return tf.matmul(hidden, layer4_weights) + layer4_biases\n",
    "  \n",
    "  # Training computation.\n",
    "  logits = model(tf_train_dataset)\n",
    "  loss = tf.reduce_mean(\n",
    "    tf.nn.softmax_cross_entropy_with_logits(labels=tf_train_labels, logits=logits))\n",
    "    \n",
    "  # Optimizer.\n",
    "  optimizer = tf.train.GradientDescentOptimizer(0.05).minimize(loss)\n",
    "  \n",
    "  # Predictions for the training, validation, and test data.\n",
    "  train_prediction = tf.nn.softmax(logits)\n",
    "  valid_prediction = tf.nn.softmax(model(tf_valid_dataset))\n",
    "  test_prediction = tf.nn.softmax(model(tf_test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "cellView": "both",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "output_extras": [
      {
       "item_id": 37
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 63292,
     "status": "ok",
     "timestamp": 1446658966251,
     "user": {
      "color": "",
      "displayName": "",
      "isAnonymous": false,
      "isMe": true,
      "permissionId": "",
      "photoUrl": "",
      "sessionId": "0",
      "userId": ""
     },
     "user_tz": 480
    },
    "id": "noKFb2UovVFR",
    "outputId": "28941338-2ef9-4088-8bd1-44295661e628",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized\n",
      "Minibatch loss at step 0: 3.620249\n",
      "Minibatch accuracy: 6.2%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 500: 0.340294\n",
      "Minibatch accuracy: 89.1%\n",
      "Validation accuracy: 83.4%\n",
      "Minibatch loss at step 1000: 0.455957\n",
      "Minibatch accuracy: 89.1%\n",
      "Validation accuracy: 85.5%\n",
      "Minibatch loss at step 1500: 0.699348\n",
      "Minibatch accuracy: 82.8%\n",
      "Validation accuracy: 86.9%\n",
      "Minibatch loss at step 2000: 0.404987\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 86.6%\n",
      "Minibatch loss at step 2500: 0.153669\n",
      "Minibatch accuracy: 96.9%\n",
      "Validation accuracy: 87.6%\n",
      "Minibatch loss at step 3000: 0.316075\n",
      "Minibatch accuracy: 89.1%\n",
      "Validation accuracy: 87.8%\n",
      "Minibatch loss at step 3500: 0.339815\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 88.2%\n",
      "Minibatch loss at step 4000: 0.472506\n",
      "Minibatch accuracy: 82.8%\n",
      "Validation accuracy: 88.3%\n",
      "Minibatch loss at step 4500: 0.295269\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 88.4%\n",
      "Minibatch loss at step 5000: 0.295001\n",
      "Minibatch accuracy: 95.3%\n",
      "Validation accuracy: 88.8%\n",
      "Minibatch loss at step 5500: 0.275190\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 88.8%\n",
      "Minibatch loss at step 6000: 0.371068\n",
      "Minibatch accuracy: 89.1%\n",
      "Validation accuracy: 89.1%\n",
      "Minibatch loss at step 6500: 0.431759\n",
      "Minibatch accuracy: 85.9%\n",
      "Validation accuracy: 88.9%\n",
      "Minibatch loss at step 7000: 0.222207\n",
      "Minibatch accuracy: 95.3%\n",
      "Validation accuracy: 89.1%\n",
      "Minibatch loss at step 7500: 0.288509\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 89.4%\n",
      "Minibatch loss at step 8000: 0.453040\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 89.6%\n",
      "Minibatch loss at step 8500: 0.301979\n",
      "Minibatch accuracy: 89.1%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss at step 9000: 0.235527\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 89.7%\n",
      "Minibatch loss at step 9500: 0.450141\n",
      "Minibatch accuracy: 84.4%\n",
      "Validation accuracy: 89.8%\n",
      "Minibatch loss at step 10000: 0.276167\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 89.9%\n",
      "Test accuracy: 95.5%\n"
     ]
    }
   ],
   "source": [
    "num_steps = 10001\n",
    "\n",
    "with tf.Session(graph=graph) as session:\n",
    "  tf.global_variables_initializer().run()\n",
    "  print('Initialized')\n",
    "  for step in range(num_steps):\n",
    "    offset = (step * batch_size) % (train_labels.shape[0] - batch_size)\n",
    "    batch_data = train_dataset[offset:(offset + batch_size), :, :, :]\n",
    "    batch_labels = train_labels[offset:(offset + batch_size), :]\n",
    "    feed_dict = {tf_train_dataset : batch_data, tf_train_labels : batch_labels}\n",
    "    _, l, predictions = session.run(\n",
    "      [optimizer, loss, train_prediction], feed_dict=feed_dict)\n",
    "    if (step % 500 == 0):\n",
    "      print('Minibatch loss at step %d: %f' % (step, l))\n",
    "      print('Minibatch accuracy: %.1f%%' % accuracy(predictions, batch_labels))\n",
    "      print('Validation accuracy: %.1f%%' % accuracy(\n",
    "        valid_prediction.eval(), valid_labels))\n",
    "  print('Test accuracy: %.1f%%' % accuracy(test_prediction.eval(), test_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KedKkn4EutIK"
   },
   "source": [
    "---\n",
    "Problem 1\n",
    "---------\n",
    "\n",
    "The convolutional model above uses convolutions with stride 2 to reduce the dimensionality. Replace the strides by a max pooling operation (`nn.max_pool()`) of stride 2 and kernel size 2.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[64, 14, 14, 16]\n",
      "[64, 7, 7, 16]\n",
      "[10000, 14, 14, 16]\n",
      "[10000, 7, 7, 16]\n",
      "[10000, 14, 14, 16]\n",
      "[10000, 7, 7, 16]\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "patch_size = 5\n",
    "depth = 16\n",
    "num_hidden = 64\n",
    "\n",
    "graph = tf.Graph()\n",
    "\n",
    "with graph.as_default():\n",
    "\n",
    "  # Input data.\n",
    "  tf_train_dataset = tf.placeholder(\n",
    "    tf.float32, shape=(batch_size, image_size, image_size, num_channels))\n",
    "  tf_train_labels = tf.placeholder(tf.float32, shape=(batch_size, num_labels))\n",
    "  tf_valid_dataset = tf.constant(valid_dataset)\n",
    "  tf_test_dataset = tf.constant(test_dataset)\n",
    "  \n",
    "  # Variables.\n",
    "  layer1_weights = tf.Variable(tf.truncated_normal(\n",
    "      [patch_size, patch_size, num_channels, depth], stddev=0.1))\n",
    "  layer1_biases = tf.Variable(tf.zeros([depth]))\n",
    "  layer2_weights = tf.Variable(tf.truncated_normal(\n",
    "      [patch_size, patch_size, depth, depth], stddev=0.1))\n",
    "  layer2_biases = tf.Variable(tf.constant(1.0, shape=[depth]))#why is this initialized to 1 and the last one to 0?\n",
    "  layer3_weights = tf.Variable(tf.truncated_normal(\n",
    "      [image_size // 4 * image_size // 4 * depth, num_hidden], stddev=0.1))\n",
    "  layer3_biases = tf.Variable(tf.constant(1.0, shape=[num_hidden]))\n",
    "  layer4_weights = tf.Variable(tf.truncated_normal(\n",
    "      [num_hidden, num_labels], stddev=0.1))\n",
    "  layer4_biases = tf.Variable(tf.constant(1.0, shape=[num_labels]))\n",
    "  \n",
    "  # Model\n",
    "  def model(data):\n",
    "    conv = tf.nn.conv2d(data, layer1_weights, [1, 1, 1, 1], padding='SAME')#stride of 1\n",
    "    hidden = tf.nn.relu(conv + layer1_biases)\n",
    "    pooled = tf.nn.max_pool(hidden, ksize = [1, 2, 2, 1], strides = [1, 2, 2, 1], padding = 'SAME')\n",
    "    print(pooled.get_shape().as_list())\n",
    "    conv = tf.nn.conv2d(pooled, layer2_weights, [1, 1, 1, 1], padding='SAME')#stride of 1\n",
    "    hidden = tf.nn.relu(conv + layer2_biases)\n",
    "    pooled = tf.nn.max_pool(hidden, ksize = [1, 2, 2, 1], strides = [1, 2, 2, 1], padding = 'SAME')\n",
    "    shape = pooled.get_shape().as_list()\n",
    "    print(shape)\n",
    "    reshape = tf.reshape(pooled, [shape[0], shape[1] * shape[2] * shape[3]])#flatten the image for the FC layers\n",
    "    hidden = tf.nn.relu(tf.matmul(reshape, layer3_weights) + layer3_biases)\n",
    "    return tf.matmul(hidden, layer4_weights) + layer4_biases\n",
    "  \n",
    "  # Training computation.\n",
    "  logits = model(tf_train_dataset)\n",
    "  loss = tf.reduce_mean(\n",
    "    tf.nn.softmax_cross_entropy_with_logits(labels=tf_train_labels, logits=logits))\n",
    "    \n",
    "  # Optimizer.\n",
    "  optimizer = tf.train.GradientDescentOptimizer(0.05).minimize(loss)\n",
    "  \n",
    "  # Predictions for the training, validation, and test data.\n",
    "  train_prediction = tf.nn.softmax(logits)\n",
    "  valid_prediction = tf.nn.softmax(model(tf_valid_dataset))\n",
    "  test_prediction = tf.nn.softmax(model(tf_test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized\n",
      "Minibatch loss at step 0: 3.226361\n",
      "Minibatch accuracy: 10.9%\n",
      "Validation accuracy: 9.1%\n",
      "Minibatch loss at step 1000: 0.461887\n",
      "Minibatch accuracy: 85.9%\n",
      "Validation accuracy: 85.5%\n",
      "Minibatch loss at step 2000: 0.380003\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 86.7%\n",
      "Minibatch loss at step 3000: 0.319473\n",
      "Minibatch accuracy: 89.1%\n",
      "Validation accuracy: 88.0%\n",
      "Minibatch loss at step 4000: 0.556612\n",
      "Minibatch accuracy: 84.4%\n",
      "Validation accuracy: 88.2%\n",
      "Minibatch loss at step 5000: 0.311766\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 88.7%\n",
      "Minibatch loss at step 6000: 0.402862\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 88.9%\n",
      "Minibatch loss at step 7000: 0.198159\n",
      "Minibatch accuracy: 95.3%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss at step 8000: 0.509191\n",
      "Minibatch accuracy: 85.9%\n",
      "Validation accuracy: 89.4%\n",
      "Minibatch loss at step 9000: 0.285312\n",
      "Minibatch accuracy: 89.1%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss at step 10000: 0.298528\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 89.6%\n",
      "Test accuracy: 95.3%\n"
     ]
    }
   ],
   "source": [
    "num_steps = 10001\n",
    "test_preds = 0\n",
    "\n",
    "with tf.Session(graph=graph) as session:\n",
    "  tf.global_variables_initializer().run()\n",
    "  print('Initialized')\n",
    "  for step in range(num_steps):\n",
    "    offset = (step * batch_size) % (train_labels.shape[0] - batch_size)\n",
    "    batch_data = train_dataset[offset:(offset + batch_size), :, :, :]\n",
    "    batch_labels = train_labels[offset:(offset + batch_size), :]\n",
    "    feed_dict = {tf_train_dataset : batch_data, tf_train_labels : batch_labels}\n",
    "    _, l, predictions = session.run(\n",
    "      [optimizer, loss, train_prediction], feed_dict=feed_dict)\n",
    "    if (step % 1000 == 0):\n",
    "      print('Minibatch loss at step %d: %f' % (step, l))\n",
    "      print('Minibatch accuracy: %.1f%%' % accuracy(predictions, batch_labels))\n",
    "      print('Validation accuracy: %.1f%%' % accuracy(\n",
    "        valid_prediction.eval(), valid_labels))\n",
    "  test_preds = test_prediction.eval()\n",
    "  print('Test accuracy: %.1f%%' % accuracy(test_preds, test_labels))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Displaying some of the images we got wrong. We can see that the dataset has some incorrect labels. However, some of the images are easy to identify by eye and the classifier still incorrectly labels them. Generally they are ones where there are rotated images, or very thin or thick lines. The classifier does not use the topology of the image as well as the eye does. It also does not realize when the font is using negative space to create a letter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted:  G\n",
      "Actual:  B\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRTKl8ItkSuEXyZTCL5Kp/wOgeGG+lK46MQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x228c8cfb978>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted:  G\n",
      "Actual:  J\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n4QeS+n9Ls/2woabxzQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2281877d4e0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted:  J\n",
      "Actual:  H\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4wLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvpW3flQAAFVlJREFUeJzt3Xt01OWZB/DvM8lACAQkXANEuRis\nijVqRLxUbamKlz2I3brS1oNbNdrVPevWtVV71rqt3XXdCtI91Qoaix6ldre10l2oKO0ptaISkHpD\nIUKUQCRAhNwgkMyzf2RwI+Z93jAzmd/g+/2cw0kyz7zze/ObefjN5HkvoqogovDEou4AEUWDyU8U\nKCY/UaCY/ESBYvITBYrJTxQoJj9RoJj8RIFi8hMFKj+bB+sn/bUAA7N5SPKQfv3M+P5S+/qgKmY8\nb7e7fV5jq9k2bVbXcnhga+cwO0c0zx3b39SIjr2t9pOSlFbyi8gMAPMB5AF4RFXvte5fgIE4Q6an\nc0jqScx4NSQ6zab5444x41vmFprxfXvt/zyGLRngjA1e/LLZNl2S7355a6d9XpDusHfrOQHM56Vx\n5plm0wNF7tyuWTzXPm43Kb/tF5E8AD8FcDGAEwDMFpETUn08IsqudD7zTwVQo6qbVHU/gF8AmJmZ\nbhFRX0sn+ccC2NLt57rkbZ8gIpUiUi0i1QfQnsbhiCiT0kn+nj54fOqDkqouUNUKVa2Io38ahyOi\nTEon+esAlHb7eRyAbel1h4iyJZ3kXw2gTEQmiEg/AFcBWJKZbhFRX0u51KeqHSJyM4Dn0FXqq1LV\ntzLWM+o1yXOXldRT6lt/S4kZ3zT1Zyn16WPnuUNzvzfRbPrYohlmfOwD1WZcCtwfM2VSqTMGAIl1\nb9uPHbdLnHpgvxlv/Ka7nNc+1C7Tt5UknLFOu1ufkFadX1WXAliazmMQUTQ4vJcoUEx+okAx+YkC\nxeQnChSTnyhQTH6iQGV1Pj/1EXXXfX3KptSZ8ds+PMWM//erp5vxM06qccZuH7PMbPvtf9xkxv/z\nGns68twXL3TGJi22xz94JuR6pwTnDR5sxsuufccZ232p/Xyun3esO5jf+6nIvPITBYrJTxQoJj9R\noJj8RIFi8hMFislPFCiW+j4DNJH6SrM120aY8fzr7KLX5M2vmvGPjNgdRV822+qxR5vxfaPtlYUL\ny+POWH7rPvvYZhTeVZFr/36KGR+8p8EZG7LbXR4FgNIxjc7YrniH2bY7XvmJAsXkJwoUk58oUEx+\nokAx+YkCxeQnChSTnyhQrPN/FnhqzpbC19276AJAZ129GfcuYW1MfU00N5tt8Zq9Erxv/6fYSWe5\nYy12nT/1M9rlutm/M+NP33eRM5Y3dJfZtn++u5YfE07pJSIPJj9RoJj8RIFi8hMFislPFCgmP1Gg\nmPxEgUqrzi8itQCa0VUW7VDVikx0irIn3pL6WgCAfytqk9hbUUPsa5PE7Zdvy3hjbvvW7faxPdov\nsZcsn1k0z4wvf9q9jsKOr51qtt250T0KoX2few2DQ2VikM8XVXVnBh6HiLKIb/uJApVu8iuA5SKy\nRkQqM9EhIsqOdN/2n62q20RkJIDnReQdVV3Z/Q7J/xQqAaAA9pprRJQ9aV35VXVb8msDgGcATO3h\nPgtUtUJVK+LeqRhElC0pJ7+IDBSRooPfA7gQwJuZ6hgR9a103vaPAvCMdJVr8gE8par2PEYiyhkp\nJ7+qbgJwcgb7Qqmy6uVq1/FjnjK9r5aeVp3fx7NOgRxXZscL3e07m5pS6tJBu65vNeP3fuierw8A\n2u5u3zjdXmtgYpX7DXujtVHCIVjqIwoUk58oUEx+okAx+YkCxeQnChSTnyhQXLo7cL6VnmVAgX2H\ntrbUj51nb/+tHfZ20x+eU2w//u7EYffpoFhRkRn/zakLzPisn3zHjJdO2OqMaac91Tn/92ucMdHe\nPx+88hMFislPFCgmP1GgmPxEgWLyEwWKyU8UKCY/UaBY5/8ssJa4VntabLzVLvRLP3sLbi9rurFn\naW6fPdPsqa/FK1NfOWrPpSea8UnxP5nx0qc2mfF3vz3B/dhV9u9lT+G2m3bHKz9RoJj8RIFi8hMF\nislPFCgmP1GgmPxEgWLyEwWKdf6DPNtF++aeW7TTrrX7lteW/NSfJvVMaR+y9C0z3rl3b8rH9vEt\n+x0rtLd3O2/yRjO+/Z6RzpjnGUHjFfbS3Pfs/JwZb5p2jBkv2OV+vcX++JrZ1nw9sM5PRD5MfqJA\nMfmJAsXkJwoUk58oUEx+okAx+YkC5S0gi0gVgMsANKjqlORtxQCeBjAeQC2AK1X1MDYHjkDMU6f3\nbAftW0O+L6V1bM/vnWhuTv2xe8EaH+H7vVpmnGTGP2qvNeOdG95z9ytur1Pwg/IlZnxZ4+fNeOto\n+7o67v5qZ0w9z5l53jJc5/85gBmH3HY7gBWqWgZgRfJnIjqCeJNfVVcCaDzk5pkAFiW/XwTg8gz3\ni4j6WKqf+Uepaj0AJL+6x1ESUU7q87H9IlIJoBIACmCP1Sai7En1yr9dREoAIPm1wXVHVV2gqhWq\nWhFH6gsqElFmpZr8SwDMSX4/B8CzmekOEWWLN/lFZDGAVQCOE5E6EbkWwL0ALhCRjQAuSP5MREcQ\n72d+VZ3tCE3PcF/S4pvz7q2Ve+bzN9x0pjM2fNYWs+3VY1eZ8WH5LWb8p1u+ZMZ3POGeO15cZR/b\n93t7edYiSGdt/m1X2PP961e7174HgEnY7ozFysabbWcNtM/bd39/vBmf/PCrZlx9Cy1kAUf4EQWK\nyU8UKCY/UaCY/ESBYvITBYrJTxSoI2rpbquc5yvltX7lDDP+Nz/4nRk/ecCDzthdNfa8pruf+2sz\nHm+yy21aZi8j/Xe3LnPG5n/BrshO/uZaMy75cTPuW5bcWp5b+tsjPm8sX2nGn688x4zHpriX137n\ntvSGmp/w7+4yIgB0eKaIp/NazhRe+YkCxeQnChSTnyhQTH6iQDH5iQLF5CcKFJOfKFA5VedPZ1ru\nB3edZbb9l288accf+7oZP3qeux7ef1+t2bYMdjxdy2LDnLG8++w6fdNV9viHwYtfTqlPHx//qCHO\nWP3XTzTbjok/bcbbSgrM+IA897WtZNRus+3KffbS3p1btppx31TpKJeCP4hXfqJAMfmJAsXkJwoU\nk58oUEx+okAx+YkCxeQnCpSob+nlDBocK9Zp+Rc5477aZ90d7lr+8ZdsMNvu/cYAM97xvr38tsU3\nL93aphoAEnv32gdI4znyjZ3YcttUMz5yrb18dnOpPY6gX7O777Pvcq9DAACPLLzUjI9+4CUzbjnr\nL/bv9eLOSWY8Nt1+vaS9lHyKXtEVaNLGXq3Hzis/UaCY/ESBYvITBYrJTxQoJj9RoJj8RIFi8hMF\nyjufX0SqAFwGoEFVpyRvuxvA9QB2JO92p6ou9R5N7fpm4pxyu/lpTc5Y87m7PMe2a+USt+dvW+vT\na3u73daMAnkjRpjxvaeNN+PNpe6nsWOAXfJN2EMUEG86YMZH/Y9d7z4wYbQztqfTHnsx5mf2ngK+\nTa6ttQRuGWbv0/Dk/55nxifAMy4kja3Js6U3Pfw5gBk93D5PVcuT//yJT0Q5xZv8qroSQGMW+kJE\nWZTOe5ObReR1EakSkaEZ6xERZUWqyf8QgEkAygHUA7jfdUcRqRSRahGpPgD7szERZU9Kya+q21W1\nU1UTABYCcM4OUdUFqlqhqhVxeP66RERZk1Lyi0hJtx9nAXgzM90homzpTalvMYDzAQwXkToA3wdw\nvoiUo6uKVQvghj7sIxH1AW/yq+rsHm5+NOUjGuuZv3+pXfctu7XOGevw1fF986uNfeR92q6w177f\ner7nATzvvwZvsNcDGP3nPc6YdNrnpfWYQWZcVv3FjPtmpe9a6K61L1r6RbPtxH2rPI9uSxxb6owN\nidmvtVGrfaMIPNTT3lrX3zNGIDaw0N20pfdv5nN/JAIR9QkmP1GgmPxEgWLyEwWKyU8UKCY/UaCy\nu0V3YQHkRPe2zEM22s2t5bW9pTxjSi7gX3773fknO2Pxo+ylt49+wn7sguV2Oc1XhrSKeTX/cabZ\ndvJj9lTohOe8ypTJZvyyo92/2+qrh6d1bN/y180T3WXMdrWnKg9e96EZ9y687ZvSq+5HaLu8wmw6\naHOzO/iOPTW9O175iQLF5CcKFJOfKFBMfqJAMfmJAsXkJwoUk58oUFmt83cOyEPjiUXO+LDX3Etz\nA4CmMQ3SqqsCQNvF7jo+ABS+7z5V42583T62R7qbpG9YeLozVrjZXrq78217a3OfzXfYL6G6J9xL\nYI/ZbW+xHSt0T10F/HX+thHu18Rr7fbrpeN99/RxAPaUXPjHZuSXuJc0319k9y2x7m33cXWf2bY7\nXvmJAsXkJwoUk58oUEx+okAx+YkCxeQnChSTnyhQWa3zJ/KBvSPc9dHYth3OGAB0Gstz++br+xRs\n92yzPcV9qvJOPM5+8P323PGGc0eZ8Wk32ltVb3jdfV7G/atdS/fWq8/8vBkvHtxixoc84K5Jw7uc\nunfWvKnDGCbwQot7XQkAQMKz/kOaaw3s+tJ4Z2z485vNtumdlf/HKz9RoJj8RIFi8hMFislPFCgm\nP1GgmPxEgWLyEwXKW+cXkVIAjwMYDSABYIGqzheRYgBPAxgPoBbAlar6kfVYif5A6wSjfuqpjZo8\ndVnE7G2ufVtRF5S7178f9PBOs+2Xh6034xv32nX+5U941t6f567l+/Yj0HZ7fEPNDfZ5O/aH9hbf\nZr3b95zE0tsmO97iHv/w0q6JdmOpN8O+On7H9NPMeNEH7vPeUW/vGWCet8MY7tKbK38HgFtV9XgA\n0wDcJCInALgdwApVLQOwIvkzER0hvMmvqvWqujb5fTOA9QDGApgJYFHybosAXN5XnSSizDusz/wi\nMh7AKQBeATBKVeuBrv8gAIzMdOeIqO/0OvlFZBCAXwG4RVXtxfY+2a5SRKpFpLqzxR4HTkTZ06vk\nF5E4uhL/SVX9dfLm7SJSkoyXAGjoqa2qLlDVClWtyBtk/3GIiLLHm/wiIgAeBbBeVed2Cy0BMCf5\n/RwAz2a+e0TUV3ozpfdsAFcDeENE1iVvuxPAvQB+KSLXAvgAwFd9DzSwcB+mlrv34W4aXmw/QKNZ\nSbT5SoGeqa0jHlrljDU9Ym+L/OzIcjPesXWbGR8NzxLXBQXOWGKfvZTzruvsMmLROvu8yEt236yp\nr75ymcIuBfoMe8O9dfrOywaabYca08cBANPsqc4dhXbfC1ascQc9JVDva7mXvMmvqi8CcL0Cpmek\nF0SUdRzhRxQoJj9RoJj8RIFi8hMFislPFCgmP1Ggsrp0d3F+K7428mVn/Ht/dY3ZfsyPa5wxq9YN\n+Ovd8NR1zXq1ZztmXx3fN8bAt1V1orXVGdt/UYXZtmmSGcaEO1Kv4wP+Wr4pzbEZsT+7p2m3v2CP\nb9jxreFmfOi79nNe8NtXzbhZy89QHd+HV36iQDH5iQLF5CcKFJOfKFBMfqJAMfmJAsXkJwqUqG/e\ncgYVHz9CL6ya5YxfM+pFs/388y5wxny1dInbc+691FhGWjz/h8Y822Dvt2vGvjEIrV85wxmrn2U/\n9uRvucdOAECitc2Mm+cF8PY9V+UNH2bGO3fuylJPDs8rugJN2mi/4JJ45ScKFJOfKFBMfqJAMfmJ\nAsXkJwoUk58oUEx+okBldT5/254CvPbc8c74Uzf+wWxfvew9Z+yFf/qC2Ta+vNruXIR8c+Lf+9Hp\nZryk3L2l8+euca9dDwAdzc1m3LuG/BFax/etBeCt43vaHwnnhVd+okAx+YkCxeQnChSTnyhQTH6i\nQDH5iQLF5CcKlLfOLyKlAB4HMBpAAsACVZ0vIncDuB7AjuRd71TVpdZj9d91ABMfr3PG1/ytPff8\nzuHvOmOVj6412172xhwz3rZipBk/qsa9/nz7ELsW3jDNXof936b/lxl/sLbUjA+8osEZ6zDW9AeQ\ntb3gc066dfgjoI7v05tBPh0AblXVtSJSBGCNiDyfjM1T1R/3XfeIqK94k19V6wHUJ79vFpH1AMb2\ndceIqG8d1md+ERkP4BQAryRvullEXheRKhEZ6mhTKSLVIlK9v9OzJBQRZU2vk19EBgH4FYBbVLUJ\nwEMAJgEoR9c7g/t7aqeqC1S1QlUr+uXZe84RUfb0KvlFJI6uxH9SVX8NAKq6XVU7VTUBYCGAqX3X\nTSLKNG/yi4gAeBTAelWd2+32km53mwXgzcx3j4j6infpbhE5B8CfALyBrlIfANwJYDa63vIrgFoA\nNyT/OOg0WIr1DJnujO+8wd42+Y//PM8ZGxSzt+iO0uYDLWb80oXfMeOl99jbZJs+A1NPqfcOZ+nu\n3vy1/0UAPT2YWdMnotzGEX5EgWLyEwWKyU8UKCY/UaCY/ESBYvITBSqrS3dD7GWqhz+8ymx+QfMt\nztgxN20w294+ZpkZL4odMOMP7jzXGfvtc+4tsgGg7CebzHjph546vnf5bGObbNbxyYFXfqJAMfmJ\nAsXkJwoUk58oUEx+okAx+YkCxeQnCpR3Pn9GDyayA8D73W4aDmBn1jpweHK1b7naL4B9S1Um+3aM\nqo7ozR2zmvyfOrhItapWRNYBQ672LVf7BbBvqYqqb3zbTxQoJj9RoKJO/gURH9+Sq33L1X4B7Fuq\nIulbpJ/5iSg6UV/5iSgikSS/iMwQkXdFpEZEbo+iDy4iUisib4jIOhGpjrgvVSLSICJvdrutWESe\nF5GNya89bpMWUd/uFpGtyXO3TkQuiahvpSLyBxFZLyJvicg/JG+P9NwZ/YrkvGX9bb+I5AHYAOAC\nAHUAVgOYrapvZ7UjDiJSC6BCVSOvCYvIuQBaADyuqlOSt90HoFFV703+xzlUVb+bI327G0BL1Ds3\nJzeUKem+szSAywFcgwjPndGvKxHBeYviyj8VQI2qblLV/QB+AWBmBP3Ieaq6EkDjITfPBLAo+f0i\ndL14ss7Rt5ygqvWqujb5fTOAgztLR3rujH5FIorkHwtgS7ef65BbW34rgOUiskZEKqPuTA9GHdwZ\nKfl1ZMT9OZR35+ZsOmRn6Zw5d6nseJ1pUSR/T7v/5FLJ4WxVPRXAxQBuSr69pd7p1c7N2dLDztI5\nIdUdrzMtiuSvA1Da7edxALZF0I8eqeq25NcGAM8g93Yf3n5wk9Tk14aI+/OxXNq5uaedpZED5y6X\ndryOIvlXAygTkQki0g/AVQCWRNCPTxGRgck/xEBEBgK4ELm3+/ASAHOS388B8GyEffmEXNm52bWz\nNCI+d7m243Ukg3ySpYwHAOQBqFLVH2W9Ez0QkYnoutoDXSsbPxVl30RkMYDz0TXrazuA7wP4DYBf\nAjgawAcAvqqqWf/Dm6Nv5+Mwd27uo765dpZ+BRGeu0zueJ2R/nCEH1GYOMKPKFBMfqJAMfmJAsXk\nJwoUk58oUEx+okAx+YkCxeQnCtT/AQVmUAqo1SNxAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x228c2d07390>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted:  H\n",
      "Actual:  A\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nhB9IivADSRF+ICnCDyT1fyJHUQ6cj2xrAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2281a533f98>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted:  B\n",
      "Actual:  C\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x228c2d7b1d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted:  E\n",
      "Actual:  C\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x228ec925908>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted:  G\n",
      "Actual:  B\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQRF+ICjCDwT1/3i7km6/gLJVAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x228c2d85748>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted:  B\n",
      "Actual:  F\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRfiBpAg/kBThB5Ii/EBShB9IivADSf0/vcE+bfk8kCAAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2281a574d30>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted:  H\n",
      "Actual:  A\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x228e8a61518>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted:  G\n",
      "Actual:  I\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ndNn0z5sAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2281a554438>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_preds_num = np.argmax(test_preds, axis=1)\n",
    "test_labels_num = np.argmax(test_labels, axis=1)\n",
    "accuracy_array = test_preds_num == test_labels_num\n",
    "errors = np.where(accuracy_array == False)\n",
    "error_images = np.squeeze(test_dataset[errors,:,:,:])\n",
    "error_preds = test_preds_num[errors]\n",
    "error_labels = test_labels_num[errors]\n",
    "\n",
    "num_errors_shown= 10\n",
    "for i in range(num_errors_shown):\n",
    "  print(\"Predicted: \",chr(error_preds[i]+65))\n",
    "  print(\"Actual: \", chr(error_labels[i]+65))\n",
    "  plt.imshow(error_images[i])\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "klf21gpbAgb-"
   },
   "source": [
    "---\n",
    "Problem 2\n",
    "---------\n",
    "\n",
    "Try to get the best performance you can using a convolutional net. Look for example at the classic [LeNet5](http://yann.lecun.com/exdb/lenet/) architecture, adding Dropout, and/or adding learning rate decay.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "patch_size = 5\n",
    "depth = 16\n",
    "num_hidden = 64\n",
    "\n",
    "graph = tf.Graph()\n",
    "\n",
    "with graph.as_default():\n",
    "\n",
    "  # Input data.\n",
    "  tf_train_dataset = tf.placeholder(\n",
    "    tf.float32, shape=(batch_size, image_size, image_size, num_channels))\n",
    "  tf_train_labels = tf.placeholder(tf.float32, shape=(batch_size, num_labels))\n",
    "  tf_valid_dataset = tf.constant(valid_dataset)\n",
    "  tf_test_dataset = tf.constant(test_dataset)\n",
    "  \n",
    "  # Variables.\n",
    "  layer1_weights = tf.Variable(tf.truncated_normal(\n",
    "      [patch_size, patch_size, num_channels, depth], stddev=0.1))\n",
    "  layer1_biases = tf.Variable(tf.zeros([depth]))\n",
    "  layer2_weights = tf.Variable(tf.truncated_normal(\n",
    "      [patch_size, patch_size, depth, depth], stddev=0.1))\n",
    "  layer2_biases = tf.Variable(tf.constant(1.0, shape=[depth]))#why is this initialized to 1 and the last one to 0?\n",
    "  layer3_weights = tf.Variable(tf.truncated_normal(\n",
    "      [image_size // 4 * image_size // 4 * depth, num_hidden], stddev=0.1))\n",
    "  layer3_biases = tf.Variable(tf.constant(1.0, shape=[num_hidden]))\n",
    "  layer4_weights = tf.Variable(tf.truncated_normal(\n",
    "      [num_hidden, num_labels], stddev=0.1))\n",
    "  layer4_biases = tf.Variable(tf.constant(1.0, shape=[num_labels]))\n",
    "  \n",
    "  # Model.\n",
    "  def model(data):\n",
    "    conv = tf.nn.conv2d(data, layer1_weights, [1, 1, 1, 1], padding='SAME')#stride of 1\n",
    "    hidden = tf.nn.relu(conv + layer1_biases)\n",
    "    pooled = tf.nn.max_pool(hidden, ksize = [1, 2, 2, 1], strides = [1, 2, 2, 1], padding = 'SAME')\n",
    "    conv = tf.nn.conv2d(pooled, layer2_weights, [1, 1, 1, 1], padding='SAME')#stride of 1\n",
    "    hidden = tf.nn.relu(conv + layer2_biases)\n",
    "    pooled = tf.nn.max_pool(hidden, ksize = [1, 2, 2, 1], strides = [1, 2, 2, 1], padding = 'SAME')\n",
    "    shape = pooled.get_shape().as_list()\n",
    "    reshape = tf.reshape(pooled, [shape[0], shape[1] * shape[2] * shape[3]])#flatten the image for the FC layers\n",
    "    hidden = tf.nn.relu(tf.matmul(reshape, layer3_weights) + layer3_biases)\n",
    "    return tf.matmul(hidden, layer4_weights) + layer4_biases\n",
    "  \n",
    "  # Training computation.\n",
    "  logits = model(tf_train_dataset)\n",
    "  loss = tf.reduce_mean(\n",
    "    tf.nn.softmax_cross_entropy_with_logits(labels=tf_train_labels, logits=logits))\n",
    "    \n",
    "  # Optimizer.\n",
    "  optimizer = tf.train.GradientDescentOptimizer(0.05).minimize(loss)\n",
    "  \n",
    "  # Predictions for the training, validation, and test data.\n",
    "  train_prediction = tf.nn.softmax(logits)\n",
    "  valid_prediction = tf.nn.softmax(model(tf_valid_dataset))\n",
    "  test_prediction = tf.nn.softmax(model(tf_test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized\n",
      "Minibatch loss at step 0: 4.576417\n",
      "Minibatch accuracy: 12.5%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 1000: 0.473701\n",
      "Minibatch accuracy: 85.9%\n",
      "Validation accuracy: 85.7%\n",
      "Minibatch loss at step 2000: 0.412366\n",
      "Minibatch accuracy: 85.9%\n",
      "Validation accuracy: 87.0%\n",
      "Minibatch loss at step 3000: 0.367866\n",
      "Minibatch accuracy: 89.1%\n",
      "Validation accuracy: 87.8%\n",
      "Minibatch loss at step 4000: 0.452540\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 88.3%\n",
      "Minibatch loss at step 5000: 0.236111\n",
      "Minibatch accuracy: 96.9%\n",
      "Validation accuracy: 88.9%\n",
      "Time:  78.43014478683472\n",
      "Test accuracy: 94.7%\n"
     ]
    }
   ],
   "source": [
    "num_steps = 5001\n",
    "\n",
    "with tf.Session(graph=graph) as session:\n",
    "  tf.global_variables_initializer().run()\n",
    "  print('Initialized')\n",
    "  t1= time.time()\n",
    "  for step in range(num_steps):\n",
    "    offset = (step * batch_size) % (train_labels.shape[0] - batch_size)\n",
    "    batch_data = train_dataset[offset:(offset + batch_size), :, :, :]\n",
    "    batch_labels = train_labels[offset:(offset + batch_size), :]\n",
    "    feed_dict = {tf_train_dataset : batch_data, tf_train_labels : batch_labels}\n",
    "    _, l, predictions = session.run(\n",
    "      [optimizer, loss, train_prediction], feed_dict=feed_dict)\n",
    "    if (step % 1000 == 0):\n",
    "      print('Minibatch loss at step %d: %f' % (step, l))\n",
    "      print('Minibatch accuracy: %.1f%%' % accuracy(predictions, batch_labels))\n",
    "      print('Validation accuracy: %.1f%%' % accuracy(\n",
    "        valid_prediction.eval(), valid_labels))\n",
    "  t2 = time.time()\n",
    "  print(\"Time: \", t2-t1)\n",
    "  test_preds = test_prediction.eval()\n",
    "  print('Test accuracy: %.1f%%' % accuracy(test_preds, test_labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trunc_valid_X = valid_dataset[:1000]\n",
    "trunc_test_X = test_dataset[:1000]\n",
    "trunc_valid_y = valid_labels[:1000]\n",
    "trunc_test_y = test_labels[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized\n",
      "Initialized\n",
      "Initialized\n",
      "Initialized\n",
      "Initialized\n",
      "Initialized\n",
      "Initialized\n",
      "Initialized\n",
      "Initialized\n",
      "Initialized\n",
      "Initialized\n",
      "Initialized\n",
      "Initialized\n",
      "Initialized\n",
      "Initialized\n",
      "Initialized\n",
      "Initialized\n",
      "Initialized\n",
      "Initialized\n",
      "Initialized\n",
      "Initialized\n",
      "Initialized\n",
      "Initialized\n",
      "Initialized\n",
      "Initialized\n",
      "Initialized\n",
      "Initialized\n",
      "Initialized\n",
      "Initialized\n",
      "Initialized\n",
      "Initialized\n",
      "Initialized\n",
      "Initialized\n",
      "Initialized\n",
      "Initialized\n",
      "Initialized\n",
      "Initialized\n",
      "Initialized\n",
      "Initialized\n",
      "Initialized\n",
      "Initialized\n",
      "Initialized\n",
      "Initialized\n",
      "Initialized\n",
      "Initialized\n",
      "Initialized\n",
      "Initialized\n",
      "Initialized\n"
     ]
    }
   ],
   "source": [
    "batch_size= 16\n",
    "patch_sizes_1 = [5,3]\n",
    "patch_sizes_2 = [5,3]\n",
    "depths = [16,32]#\n",
    "num_hiddens = [32,64]#\n",
    "num_steps = 10001\n",
    "learning_rates = [.05,.01,.005]#\n",
    "\n",
    "cols = ['patch size 1', 'patch size 2', 'depth',\n",
    "                                 'num_hidden','learning_rate', 'training time',\n",
    "                                 'validation accuracy', 'testing accuracy']\n",
    "results = {}\n",
    "for col in cols:\n",
    "  results[col] =[]\n",
    "\n",
    "for patch_size_1, patch_size_2, depth, num_hidden, learning_rate in itertools.product(patch_sizes_1, \n",
    "                    patch_sizes_2, depths,num_hiddens, learning_rates):\n",
    "  results['patch size 1'].append(patch_size_1)\n",
    "  results['patch size 2'].append(patch_size_2)\n",
    "  results['depth'].append(depth)\n",
    "  results['num_hidden'].append(num_hidden)\n",
    "  results['learning_rate'].append(learning_rate)\n",
    "  \n",
    "  graph = tf.Graph()\n",
    "  with graph.as_default():\n",
    "    # Input data.\n",
    "    tf_train_dataset = tf.placeholder(\n",
    "      tf.float32, shape=(batch_size, image_size, image_size, num_channels))\n",
    "    tf_train_labels = tf.placeholder(tf.float32, shape=(batch_size, num_labels))\n",
    "    tf_valid_dataset = tf.constant(trunc_valid_X)\n",
    "    tf_test_dataset = tf.constant(trunc_test_X)\n",
    "    # Variables.\n",
    "    layer1_weights = tf.Variable(tf.truncated_normal(\n",
    "        [patch_size_1, patch_size_1, num_channels, depth], stddev=0.1))\n",
    "    layer1_biases = tf.Variable(tf.zeros([depth]))\n",
    "    layer2_weights = tf.Variable(tf.truncated_normal(\n",
    "        [patch_size_2, patch_size_2, depth, depth], stddev=0.1))\n",
    "    layer2_biases = tf.Variable(tf.constant(1.0, shape=[depth]))#why is this initialized to 1 and the last one to 0?\n",
    "    layer3_weights = tf.Variable(tf.truncated_normal(\n",
    "        [image_size // 4 * image_size // 4 * depth, num_hidden], stddev=0.1))\n",
    "    layer3_biases = tf.Variable(tf.constant(1.0, shape=[num_hidden]))\n",
    "    layer4_weights = tf.Variable(tf.truncated_normal(\n",
    "        [num_hidden, num_labels], stddev=0.1))\n",
    "    layer4_biases = tf.Variable(tf.constant(1.0, shape=[num_labels]))\n",
    "    # Model.\n",
    "    def model(data):\n",
    "      conv = tf.nn.conv2d(data, layer1_weights, [1, 1, 1, 1], padding='SAME')#stride of 1\n",
    "      hidden = tf.nn.relu(conv + layer1_biases)\n",
    "      pooled = tf.nn.max_pool(hidden, ksize = [1, 2, 2, 1], strides = [1, 2, 2, 1], padding = 'SAME')\n",
    "      conv = tf.nn.conv2d(pooled, layer2_weights, [1, 1, 1, 1], padding='SAME')#stride of 1\n",
    "      hidden = tf.nn.relu(conv + layer2_biases)\n",
    "      pooled = tf.nn.max_pool(hidden, ksize = [1, 2, 2, 1], strides = [1, 2, 2, 1], padding = 'SAME')\n",
    "      shape = pooled.get_shape().as_list()\n",
    "      reshape = tf.reshape(pooled, [shape[0], shape[1] * shape[2] * shape[3]])#flatten the image for the FC layers\n",
    "      hidden = tf.nn.relu(tf.matmul(reshape, layer3_weights) + layer3_biases)\n",
    "      return tf.matmul(hidden, layer4_weights) + layer4_biases\n",
    "    # Training computation.\n",
    "    logits = model(tf_train_dataset)\n",
    "    loss = tf.reduce_mean(\n",
    "      tf.nn.softmax_cross_entropy_with_logits(labels=tf_train_labels, logits=logits))\n",
    "    # Optimizer.\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss)\n",
    "    # Predictions for the training, validation, and test data.\n",
    "    train_prediction = tf.nn.softmax(logits)\n",
    "    valid_prediction = tf.nn.softmax(model(tf_valid_dataset))\n",
    "    test_prediction = tf.nn.softmax(model(tf_test_dataset))\n",
    "\n",
    "  with tf.Session(graph=graph) as session:\n",
    "    tf.global_variables_initializer().run()\n",
    "    print('Initialized')\n",
    "    t1= time.time()\n",
    "    validation_accuracies = []\n",
    "    for step in range(num_steps):\n",
    "      offset = (step * batch_size) % (train_labels.shape[0] - batch_size)\n",
    "      batch_data = train_dataset[offset:(offset + batch_size), :, :, :]\n",
    "      batch_labels = train_labels[offset:(offset + batch_size), :]\n",
    "      feed_dict = {tf_train_dataset : batch_data, tf_train_labels : batch_labels}\n",
    "      _, l, predictions = session.run(\n",
    "        [optimizer, loss, train_prediction], feed_dict=feed_dict)\n",
    "      if (step % 1000 == 0):\n",
    "        validation_accuracies.append(accuracy(valid_prediction.eval(), trunc_valid_y))\n",
    "    t2 = time.time()\n",
    "    results['training time'].append(t2-t1)\n",
    "    results['validation accuracy'].append(validation_accuracies)\n",
    "    results['testing accuracy'].append(accuracy(test_prediction.eval(), trunc_test_y))\n",
    "\n",
    "    \n",
    "winsound.Beep(500,1000)\n",
    "results = pd.DataFrame(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>depth</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>num_hidden</th>\n",
       "      <th>patch size 1</th>\n",
       "      <th>patch size 2</th>\n",
       "      <th>testing accuracy</th>\n",
       "      <th>training time</th>\n",
       "      <th>validation accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>0.050</td>\n",
       "      <td>64</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>94.9</td>\n",
       "      <td>48.658773</td>\n",
       "      <td>[12.0, 82.9, 85.4, 85.4, 86.2, 87.1, 87.4, 87....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16</td>\n",
       "      <td>0.050</td>\n",
       "      <td>64</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>94.7</td>\n",
       "      <td>52.067096</td>\n",
       "      <td>[8.9, 84.0, 85.2, 86.0, 87.3, 87.1, 87.9, 87.8...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>32</td>\n",
       "      <td>0.050</td>\n",
       "      <td>32</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>94.7</td>\n",
       "      <td>77.880677</td>\n",
       "      <td>[11.8, 83.8, 85.8, 85.8, 87.4, 86.6, 87.8, 87....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>16</td>\n",
       "      <td>0.050</td>\n",
       "      <td>32</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>94.4</td>\n",
       "      <td>48.978811</td>\n",
       "      <td>[10.9, 83.3, 83.8, 85.3, 85.1, 86.1, 86.4, 86....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>16</td>\n",
       "      <td>0.050</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>94.4</td>\n",
       "      <td>50.998809</td>\n",
       "      <td>[12.0, 82.8, 85.4, 85.0, 85.6, 85.7, 87.3, 87....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>32</td>\n",
       "      <td>0.050</td>\n",
       "      <td>64</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>94.4</td>\n",
       "      <td>78.389090</td>\n",
       "      <td>[9.9, 83.6, 85.9, 84.9, 86.4, 87.5, 87.0, 87.7...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>32</td>\n",
       "      <td>0.050</td>\n",
       "      <td>64</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>94.3</td>\n",
       "      <td>71.399626</td>\n",
       "      <td>[11.4, 82.6, 84.6, 85.3, 86.3, 86.1, 87.0, 87....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>32</td>\n",
       "      <td>0.050</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>93.9</td>\n",
       "      <td>77.253256</td>\n",
       "      <td>[10.0, 81.7, 85.3, 85.5, 86.3, 86.7, 86.2, 86....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16</td>\n",
       "      <td>0.050</td>\n",
       "      <td>32</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>93.8</td>\n",
       "      <td>51.857357</td>\n",
       "      <td>[11.2, 84.0, 85.8, 86.4, 86.9, 86.9, 88.1, 88....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>32</td>\n",
       "      <td>0.010</td>\n",
       "      <td>32</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>93.8</td>\n",
       "      <td>77.595005</td>\n",
       "      <td>[11.0, 81.5, 82.9, 83.8, 84.7, 84.5, 85.0, 84....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>16</td>\n",
       "      <td>0.050</td>\n",
       "      <td>32</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>93.7</td>\n",
       "      <td>51.264191</td>\n",
       "      <td>[11.7, 81.9, 84.5, 85.5, 86.4, 87.2, 87.1, 88....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>32</td>\n",
       "      <td>0.010</td>\n",
       "      <td>32</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>93.6</td>\n",
       "      <td>78.080317</td>\n",
       "      <td>[13.8, 80.6, 83.1, 84.0, 84.2, 84.6, 84.5, 84....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>32</td>\n",
       "      <td>0.010</td>\n",
       "      <td>64</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>93.5</td>\n",
       "      <td>78.223794</td>\n",
       "      <td>[16.5, 82.4, 83.7, 84.5, 85.5, 85.8, 85.7, 86....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16</td>\n",
       "      <td>0.010</td>\n",
       "      <td>32</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>93.4</td>\n",
       "      <td>51.221874</td>\n",
       "      <td>[9.2, 82.0, 84.0, 84.2, 84.2, 84.4, 84.9, 85.3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>32</td>\n",
       "      <td>0.050</td>\n",
       "      <td>32</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>93.4</td>\n",
       "      <td>71.133410</td>\n",
       "      <td>[10.0, 79.6, 83.0, 83.7, 84.8, 85.2, 85.8, 86....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>32</td>\n",
       "      <td>0.050</td>\n",
       "      <td>32</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>93.4</td>\n",
       "      <td>76.349626</td>\n",
       "      <td>[11.2, 10.0, 11.2, 9.9, 9.8, 10.9, 9.9, 10.1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>32</td>\n",
       "      <td>0.050</td>\n",
       "      <td>32</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>93.4</td>\n",
       "      <td>71.692026</td>\n",
       "      <td>[11.2, 82.0, 85.2, 85.5, 86.7, 86.1, 86.8, 87....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16</td>\n",
       "      <td>0.010</td>\n",
       "      <td>64</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>93.4</td>\n",
       "      <td>52.881181</td>\n",
       "      <td>[11.0, 82.0, 83.1, 83.7, 85.0, 84.8, 85.5, 85....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>32</td>\n",
       "      <td>0.005</td>\n",
       "      <td>64</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>93.3</td>\n",
       "      <td>78.160438</td>\n",
       "      <td>[8.0, 80.8, 81.8, 83.4, 83.6, 84.1, 84.1, 83.5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16</td>\n",
       "      <td>0.005</td>\n",
       "      <td>32</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>93.2</td>\n",
       "      <td>52.769863</td>\n",
       "      <td>[11.9, 77.0, 80.7, 81.4, 82.3, 82.4, 83.0, 82....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>32</td>\n",
       "      <td>0.010</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>93.1</td>\n",
       "      <td>77.580091</td>\n",
       "      <td>[10.5, 81.1, 82.6, 84.2, 85.5, 85.2, 85.4, 85....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>16</td>\n",
       "      <td>0.010</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>93.0</td>\n",
       "      <td>48.165492</td>\n",
       "      <td>[11.7, 80.1, 80.7, 82.1, 83.1, 83.7, 83.9, 84....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>0.010</td>\n",
       "      <td>64</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>93.0</td>\n",
       "      <td>49.097251</td>\n",
       "      <td>[10.2, 80.8, 82.0, 83.3, 84.1, 84.8, 84.6, 85....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>16</td>\n",
       "      <td>0.010</td>\n",
       "      <td>32</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>92.9</td>\n",
       "      <td>48.361005</td>\n",
       "      <td>[11.0, 79.2, 80.9, 82.3, 83.1, 83.0, 84.7, 84....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>32</td>\n",
       "      <td>0.005</td>\n",
       "      <td>64</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>92.9</td>\n",
       "      <td>71.152062</td>\n",
       "      <td>[10.3, 79.9, 83.0, 82.7, 84.3, 84.3, 84.5, 84....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>16</td>\n",
       "      <td>0.010</td>\n",
       "      <td>32</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>92.8</td>\n",
       "      <td>48.523540</td>\n",
       "      <td>[9.9, 78.9, 80.0, 81.0, 82.7, 83.5, 84.1, 83.3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>16</td>\n",
       "      <td>0.010</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>92.7</td>\n",
       "      <td>51.973259</td>\n",
       "      <td>[8.2, 81.3, 82.8, 83.1, 83.5, 84.9, 85.6, 85.3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>32</td>\n",
       "      <td>0.005</td>\n",
       "      <td>32</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>92.6</td>\n",
       "      <td>78.335232</td>\n",
       "      <td>[14.4, 78.3, 81.6, 82.6, 83.2, 83.6, 83.6, 83....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>32</td>\n",
       "      <td>0.010</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>92.6</td>\n",
       "      <td>71.741018</td>\n",
       "      <td>[10.0, 81.0, 82.3, 82.9, 83.0, 84.2, 84.2, 84....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>32</td>\n",
       "      <td>0.010</td>\n",
       "      <td>64</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>92.5</td>\n",
       "      <td>71.106907</td>\n",
       "      <td>[11.7, 81.6, 83.1, 83.5, 85.0, 85.3, 84.4, 85....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>16</td>\n",
       "      <td>0.010</td>\n",
       "      <td>32</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>92.4</td>\n",
       "      <td>51.486240</td>\n",
       "      <td>[11.0, 81.0, 81.9, 82.6, 83.7, 83.6, 84.3, 84....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>32</td>\n",
       "      <td>0.010</td>\n",
       "      <td>32</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>92.4</td>\n",
       "      <td>71.062610</td>\n",
       "      <td>[10.9, 81.1, 83.5, 84.1, 84.3, 85.1, 85.0, 84....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>16</td>\n",
       "      <td>0.005</td>\n",
       "      <td>64</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>92.3</td>\n",
       "      <td>51.937065</td>\n",
       "      <td>[12.5, 79.0, 80.9, 81.0, 81.7, 83.5, 84.4, 84....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>16</td>\n",
       "      <td>0.005</td>\n",
       "      <td>64</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>92.3</td>\n",
       "      <td>49.245064</td>\n",
       "      <td>[10.2, 78.2, 80.8, 81.4, 82.2, 82.5, 84.2, 85....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>16</td>\n",
       "      <td>0.005</td>\n",
       "      <td>32</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>92.2</td>\n",
       "      <td>51.328090</td>\n",
       "      <td>[10.9, 76.1, 80.0, 81.2, 81.8, 81.8, 82.2, 83....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>32</td>\n",
       "      <td>0.010</td>\n",
       "      <td>32</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>92.1</td>\n",
       "      <td>71.346240</td>\n",
       "      <td>[10.8, 80.4, 82.1, 82.2, 83.6, 83.2, 83.8, 83....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>16</td>\n",
       "      <td>0.005</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>91.9</td>\n",
       "      <td>51.461214</td>\n",
       "      <td>[9.8, 79.2, 81.2, 81.2, 82.7, 82.4, 83.5, 83.3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>32</td>\n",
       "      <td>0.005</td>\n",
       "      <td>32</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>91.5</td>\n",
       "      <td>77.466970</td>\n",
       "      <td>[11.3, 79.7, 80.7, 81.4, 82.2, 82.3, 82.7, 83....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>32</td>\n",
       "      <td>0.005</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>91.5</td>\n",
       "      <td>71.703370</td>\n",
       "      <td>[9.2, 79.1, 81.2, 81.4, 82.0, 82.7, 83.1, 82.7...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>32</td>\n",
       "      <td>0.005</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>91.4</td>\n",
       "      <td>77.677018</td>\n",
       "      <td>[13.1, 80.9, 82.5, 82.6, 83.7, 84.1, 83.6, 84....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>32</td>\n",
       "      <td>0.005</td>\n",
       "      <td>32</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>91.0</td>\n",
       "      <td>70.082665</td>\n",
       "      <td>[16.5, 77.2, 80.6, 81.1, 82.2, 82.3, 83.2, 83....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>16</td>\n",
       "      <td>0.005</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>90.9</td>\n",
       "      <td>48.390703</td>\n",
       "      <td>[11.8, 78.6, 81.0, 80.7, 82.0, 81.7, 82.8, 83....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>16</td>\n",
       "      <td>0.005</td>\n",
       "      <td>32</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>90.9</td>\n",
       "      <td>48.852046</td>\n",
       "      <td>[11.2, 76.9, 79.0, 80.7, 82.2, 82.4, 81.7, 83....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>32</td>\n",
       "      <td>0.005</td>\n",
       "      <td>32</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>90.7</td>\n",
       "      <td>71.277549</td>\n",
       "      <td>[12.8, 77.6, 80.0, 81.4, 82.2, 82.8, 83.9, 83....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>16</td>\n",
       "      <td>0.005</td>\n",
       "      <td>32</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>90.4</td>\n",
       "      <td>48.305845</td>\n",
       "      <td>[11.2, 76.7, 80.3, 80.0, 82.3, 81.5, 83.0, 82....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>16</td>\n",
       "      <td>0.050</td>\n",
       "      <td>32</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>9.2</td>\n",
       "      <td>48.670771</td>\n",
       "      <td>[10.2, 10.0, 11.2, 9.9, 9.8, 10.9, 9.9, 10.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>16</td>\n",
       "      <td>0.050</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>9.2</td>\n",
       "      <td>48.257285</td>\n",
       "      <td>[12.2, 10.0, 11.2, 9.9, 9.8, 10.9, 9.9, 10.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>32</td>\n",
       "      <td>0.050</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>9.2</td>\n",
       "      <td>71.498619</td>\n",
       "      <td>[10.0, 10.0, 11.2, 9.9, 9.8, 10.9, 9.9, 10.0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    depth  learning_rate  num_hidden  patch size 1  patch size 2  \\\n",
       "15     16          0.050          64             5             3   \n",
       "3      16          0.050          64             5             5   \n",
       "6      32          0.050          32             5             5   \n",
       "12     16          0.050          32             5             3   \n",
       "27     16          0.050          64             3             5   \n",
       "9      32          0.050          64             5             5   \n",
       "21     32          0.050          64             5             3   \n",
       "33     32          0.050          64             3             5   \n",
       "0      16          0.050          32             5             5   \n",
       "7      32          0.010          32             5             5   \n",
       "24     16          0.050          32             3             5   \n",
       "31     32          0.010          32             3             5   \n",
       "10     32          0.010          64             5             5   \n",
       "1      16          0.010          32             5             5   \n",
       "42     32          0.050          32             3             3   \n",
       "30     32          0.050          32             3             5   \n",
       "18     32          0.050          32             5             3   \n",
       "4      16          0.010          64             5             5   \n",
       "11     32          0.005          64             5             5   \n",
       "2      16          0.005          32             5             5   \n",
       "34     32          0.010          64             3             5   \n",
       "40     16          0.010          64             3             3   \n",
       "16     16          0.010          64             5             3   \n",
       "13     16          0.010          32             5             3   \n",
       "23     32          0.005          64             5             3   \n",
       "37     16          0.010          32             3             3   \n",
       "28     16          0.010          64             3             5   \n",
       "8      32          0.005          32             5             5   \n",
       "46     32          0.010          64             3             3   \n",
       "22     32          0.010          64             5             3   \n",
       "25     16          0.010          32             3             5   \n",
       "19     32          0.010          32             5             3   \n",
       "5      16          0.005          64             5             5   \n",
       "17     16          0.005          64             5             3   \n",
       "26     16          0.005          32             3             5   \n",
       "43     32          0.010          32             3             3   \n",
       "29     16          0.005          64             3             5   \n",
       "32     32          0.005          32             3             5   \n",
       "47     32          0.005          64             3             3   \n",
       "35     32          0.005          64             3             5   \n",
       "44     32          0.005          32             3             3   \n",
       "41     16          0.005          64             3             3   \n",
       "14     16          0.005          32             5             3   \n",
       "20     32          0.005          32             5             3   \n",
       "38     16          0.005          32             3             3   \n",
       "36     16          0.050          32             3             3   \n",
       "39     16          0.050          64             3             3   \n",
       "45     32          0.050          64             3             3   \n",
       "\n",
       "    testing accuracy  training time  \\\n",
       "15              94.9      48.658773   \n",
       "3               94.7      52.067096   \n",
       "6               94.7      77.880677   \n",
       "12              94.4      48.978811   \n",
       "27              94.4      50.998809   \n",
       "9               94.4      78.389090   \n",
       "21              94.3      71.399626   \n",
       "33              93.9      77.253256   \n",
       "0               93.8      51.857357   \n",
       "7               93.8      77.595005   \n",
       "24              93.7      51.264191   \n",
       "31              93.6      78.080317   \n",
       "10              93.5      78.223794   \n",
       "1               93.4      51.221874   \n",
       "42              93.4      71.133410   \n",
       "30              93.4      76.349626   \n",
       "18              93.4      71.692026   \n",
       "4               93.4      52.881181   \n",
       "11              93.3      78.160438   \n",
       "2               93.2      52.769863   \n",
       "34              93.1      77.580091   \n",
       "40              93.0      48.165492   \n",
       "16              93.0      49.097251   \n",
       "13              92.9      48.361005   \n",
       "23              92.9      71.152062   \n",
       "37              92.8      48.523540   \n",
       "28              92.7      51.973259   \n",
       "8               92.6      78.335232   \n",
       "46              92.6      71.741018   \n",
       "22              92.5      71.106907   \n",
       "25              92.4      51.486240   \n",
       "19              92.4      71.062610   \n",
       "5               92.3      51.937065   \n",
       "17              92.3      49.245064   \n",
       "26              92.2      51.328090   \n",
       "43              92.1      71.346240   \n",
       "29              91.9      51.461214   \n",
       "32              91.5      77.466970   \n",
       "47              91.5      71.703370   \n",
       "35              91.4      77.677018   \n",
       "44              91.0      70.082665   \n",
       "41              90.9      48.390703   \n",
       "14              90.9      48.852046   \n",
       "20              90.7      71.277549   \n",
       "38              90.4      48.305845   \n",
       "36               9.2      48.670771   \n",
       "39               9.2      48.257285   \n",
       "45               9.2      71.498619   \n",
       "\n",
       "                                  validation accuracy  \n",
       "15  [12.0, 82.9, 85.4, 85.4, 86.2, 87.1, 87.4, 87....  \n",
       "3   [8.9, 84.0, 85.2, 86.0, 87.3, 87.1, 87.9, 87.8...  \n",
       "6   [11.8, 83.8, 85.8, 85.8, 87.4, 86.6, 87.8, 87....  \n",
       "12  [10.9, 83.3, 83.8, 85.3, 85.1, 86.1, 86.4, 86....  \n",
       "27  [12.0, 82.8, 85.4, 85.0, 85.6, 85.7, 87.3, 87....  \n",
       "9   [9.9, 83.6, 85.9, 84.9, 86.4, 87.5, 87.0, 87.7...  \n",
       "21  [11.4, 82.6, 84.6, 85.3, 86.3, 86.1, 87.0, 87....  \n",
       "33  [10.0, 81.7, 85.3, 85.5, 86.3, 86.7, 86.2, 86....  \n",
       "0   [11.2, 84.0, 85.8, 86.4, 86.9, 86.9, 88.1, 88....  \n",
       "7   [11.0, 81.5, 82.9, 83.8, 84.7, 84.5, 85.0, 84....  \n",
       "24  [11.7, 81.9, 84.5, 85.5, 86.4, 87.2, 87.1, 88....  \n",
       "31  [13.8, 80.6, 83.1, 84.0, 84.2, 84.6, 84.5, 84....  \n",
       "10  [16.5, 82.4, 83.7, 84.5, 85.5, 85.8, 85.7, 86....  \n",
       "1   [9.2, 82.0, 84.0, 84.2, 84.2, 84.4, 84.9, 85.3...  \n",
       "42  [10.0, 79.6, 83.0, 83.7, 84.8, 85.2, 85.8, 86....  \n",
       "30  [11.2, 10.0, 11.2, 9.9, 9.8, 10.9, 9.9, 10.1, ...  \n",
       "18  [11.2, 82.0, 85.2, 85.5, 86.7, 86.1, 86.8, 87....  \n",
       "4   [11.0, 82.0, 83.1, 83.7, 85.0, 84.8, 85.5, 85....  \n",
       "11  [8.0, 80.8, 81.8, 83.4, 83.6, 84.1, 84.1, 83.5...  \n",
       "2   [11.9, 77.0, 80.7, 81.4, 82.3, 82.4, 83.0, 82....  \n",
       "34  [10.5, 81.1, 82.6, 84.2, 85.5, 85.2, 85.4, 85....  \n",
       "40  [11.7, 80.1, 80.7, 82.1, 83.1, 83.7, 83.9, 84....  \n",
       "16  [10.2, 80.8, 82.0, 83.3, 84.1, 84.8, 84.6, 85....  \n",
       "13  [11.0, 79.2, 80.9, 82.3, 83.1, 83.0, 84.7, 84....  \n",
       "23  [10.3, 79.9, 83.0, 82.7, 84.3, 84.3, 84.5, 84....  \n",
       "37  [9.9, 78.9, 80.0, 81.0, 82.7, 83.5, 84.1, 83.3...  \n",
       "28  [8.2, 81.3, 82.8, 83.1, 83.5, 84.9, 85.6, 85.3...  \n",
       "8   [14.4, 78.3, 81.6, 82.6, 83.2, 83.6, 83.6, 83....  \n",
       "46  [10.0, 81.0, 82.3, 82.9, 83.0, 84.2, 84.2, 84....  \n",
       "22  [11.7, 81.6, 83.1, 83.5, 85.0, 85.3, 84.4, 85....  \n",
       "25  [11.0, 81.0, 81.9, 82.6, 83.7, 83.6, 84.3, 84....  \n",
       "19  [10.9, 81.1, 83.5, 84.1, 84.3, 85.1, 85.0, 84....  \n",
       "5   [12.5, 79.0, 80.9, 81.0, 81.7, 83.5, 84.4, 84....  \n",
       "17  [10.2, 78.2, 80.8, 81.4, 82.2, 82.5, 84.2, 85....  \n",
       "26  [10.9, 76.1, 80.0, 81.2, 81.8, 81.8, 82.2, 83....  \n",
       "43  [10.8, 80.4, 82.1, 82.2, 83.6, 83.2, 83.8, 83....  \n",
       "29  [9.8, 79.2, 81.2, 81.2, 82.7, 82.4, 83.5, 83.3...  \n",
       "32  [11.3, 79.7, 80.7, 81.4, 82.2, 82.3, 82.7, 83....  \n",
       "47  [9.2, 79.1, 81.2, 81.4, 82.0, 82.7, 83.1, 82.7...  \n",
       "35  [13.1, 80.9, 82.5, 82.6, 83.7, 84.1, 83.6, 84....  \n",
       "44  [16.5, 77.2, 80.6, 81.1, 82.2, 82.3, 83.2, 83....  \n",
       "41  [11.8, 78.6, 81.0, 80.7, 82.0, 81.7, 82.8, 83....  \n",
       "14  [11.2, 76.9, 79.0, 80.7, 82.2, 82.4, 81.7, 83....  \n",
       "20  [12.8, 77.6, 80.0, 81.4, 82.2, 82.8, 83.9, 83....  \n",
       "38  [11.2, 76.7, 80.3, 80.0, 82.3, 81.5, 83.0, 82....  \n",
       "36  [10.2, 10.0, 11.2, 9.9, 9.8, 10.9, 9.9, 10.0, ...  \n",
       "39  [12.2, 10.0, 11.2, 9.9, 9.8, 10.9, 9.9, 10.0, ...  \n",
       "45  [10.0, 10.0, 11.2, 9.9, 9.8, 10.9, 9.9, 10.0, ...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_results = results.sort_values('testing accuracy', inplace = False, ascending= False)\n",
    "sorted_results"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "default_view": {},
   "name": "4_convolutions.ipynb",
   "provenance": [],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
